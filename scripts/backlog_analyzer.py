#!/usr/bin/env python3
"""
Jira ë°±ë¡œê·¸ ë²„ê·¸ ë¶„ì„ê¸°
- DEN ë³´ë“œ 31ì˜ ë°±ë¡œê·¸ì—ì„œ ë²„ê·¸ í‹°ì¼“ì„ ì¡°íšŒ
- ë°œìƒ ë¹ˆë„ë¡œ í•„í„°ë§ (Alwaysë§Œ ë¶„ì„ ëŒ€ìƒ)
- ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ìœ¼ë¡œ í•´ê²° ê°€ëŠ¥ì„± íŒë‹¨
- Slackìœ¼ë¡œ ì•Œë¦¼ ì „ì†¡
"""

import os
import sys
import json
import base64
import urllib.request
import urllib.error
from datetime import datetime
from pathlib import Path

# ì„¤ì •
JIRA_URL = "https://imagoworks.atlassian.net"
BOARD_ID = 31
PROJECT_PATH = os.path.expanduser("~/Works/devops/dentbird-solutions")
REPORT_DIR = Path(__file__).parent.parent / "reports"

# í™˜ê²½ ë³€ìˆ˜
JIRA_EMAIL = os.environ.get("JIRA_EMAIL", "")
JIRA_API_TOKEN = os.environ.get("JIRA_API_TOKEN", "")
SLACK_WEBHOOK = os.environ.get("SLACK_WEBHOOK", "")

# ì œì™¸í•  ë°œìƒ ë¹ˆë„
EXCLUDE_FREQUENCIES = ["Random", "Once", "Sometimes"]

def check_env():
    """í™˜ê²½ ë³€ìˆ˜ í™•ì¸"""
    missing = []
    if not JIRA_EMAIL:
        missing.append("JIRA_EMAIL")
    if not JIRA_API_TOKEN:
        missing.append("JIRA_API_TOKEN")
    if not SLACK_WEBHOOK:
        missing.append("SLACK_WEBHOOK")

    if missing:
        print(f"âŒ í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½: {', '.join(missing)}")
        return False

    print("âœ… í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ì™„ë£Œ")
    return True


def get_auth_header():
    """Basic ì¸ì¦ í—¤ë” ìƒì„±"""
    auth = base64.b64encode(f"{JIRA_EMAIL}:{JIRA_API_TOKEN}".encode()).decode()
    return f"Basic {auth}"


def fetch_backlog():
    """ë°±ë¡œê·¸ í‹°ì¼“ ì¡°íšŒ (ìµœì‹  ìƒì„±ìˆœ)"""
    url = f"{JIRA_URL}/rest/agile/1.0/board/{BOARD_ID}/backlog?maxResults=50&fields=key,summary,priority,status,created"

    req = urllib.request.Request(url, headers={
        "Authorization": get_auth_header(),
        "Content-Type": "application/json"
    })

    try:
        with urllib.request.urlopen(req, timeout=30) as resp:
            data = json.loads(resp.read().decode())
            issues = data.get("issues", [])

            # ìµœì‹  ìƒì„±ìˆœ ì •ë ¬ í›„ ìƒìœ„ 15ê°œ
            issues.sort(key=lambda x: x["fields"].get("created", ""), reverse=True)
            return issues[:15]
    except urllib.error.HTTPError as e:
        print(f"âŒ Jira API ì—ëŸ¬: {e.code} - {e.reason}")
        return []
    except Exception as e:
        print(f"âŒ ë°±ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []


def fetch_issue_detail(issue_key):
    """í‹°ì¼“ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
    url = f"{JIRA_URL}/rest/api/3/issue/{issue_key}"

    req = urllib.request.Request(url, headers={
        "Authorization": get_auth_header(),
        "Content-Type": "application/json"
    })

    try:
        with urllib.request.urlopen(req, timeout=30) as resp:
            return json.loads(resp.read().decode())
    except Exception as e:
        print(f"  âš ï¸ {issue_key} ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None


def extract_text_from_adf(adf):
    """ADF(Atlassian Document Format)ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    if not adf:
        return ""

    if isinstance(adf, str):
        return adf

    texts = []

    def traverse(node):
        if isinstance(node, dict):
            if node.get("type") == "text":
                texts.append(node.get("text", ""))
            for child in node.get("content", []):
                traverse(child)
        elif isinstance(node, list):
            for item in node:
                traverse(item)

    traverse(adf)
    return " ".join(texts)


def analyze_issue(issue_data):
    """í‹°ì¼“ ë¶„ì„"""
    fields = issue_data.get("fields", {})

    # ê¸°ë³¸ ì •ë³´
    key = issue_data.get("key", "")
    summary = fields.get("summary", "")
    priority = fields.get("priority", {}).get("name", "Unknown")
    created = fields.get("created", "")[:10]  # YYYY-MM-DDë§Œ

    # ë°œìƒ ë¹ˆë„ (customfield_10091)
    frequency_field = fields.get("customfield_10091", {})
    frequency = frequency_field.get("value", "Unknown") if frequency_field else "Unknown"

    # ê¸°ëŠ¥ ì˜ì—­ (customfield_10095)
    feature_area_field = fields.get("customfield_10095", {})
    feature_area = feature_area_field.get("value", "") if feature_area_field else ""

    # ì¬í˜„ ë‹¨ê³„ (customfield_10084)
    repro_steps = extract_text_from_adf(fields.get("customfield_10084"))

    # ìƒì„¸ ì„¤ëª…
    description = extract_text_from_adf(fields.get("description"))

    # ë¼ë²¨
    labels = fields.get("labels", [])

    return {
        "key": key,
        "summary": summary,
        "priority": priority,
        "created": created,
        "frequency": frequency,
        "feature_area": feature_area,
        "repro_steps": repro_steps,
        "description": description,
        "labels": labels,
        "url": f"{JIRA_URL}/browse/{key}"
    }


def search_codebase(keywords, feature_area):
    """ì½”ë“œë² ì´ìŠ¤ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰"""
    if not os.path.exists(PROJECT_PATH):
        return {"error": "í”„ë¡œì íŠ¸ ê²½ë¡œ ì—†ìŒ", "files": []}

    found_files = []

    # ê¸°ëŠ¥ ì˜ì—­ â†’ ë””ë ‰í† ë¦¬ ë§¤í•‘
    area_dirs = {
        "My Designs": ["apps/*/my-designs", "libs/*design*"],
        "Export": ["apps/*/export", "libs/*export*"],
        "Case Viewer": ["apps/*/case-viewer", "libs/*viewer*"],
        "Login / Sign up": ["apps/*/auth", "libs/*auth*"],
    }

    search_dirs = [PROJECT_PATH]
    if feature_area and feature_area in area_dirs:
        # íŠ¹ì • ì˜ì—­ ìš°ì„  ê²€ìƒ‰
        pass

    # í‚¤ì›Œë“œë¡œ grep ê²€ìƒ‰ (ê°„ë‹¨ êµ¬í˜„)
    for keyword in keywords[:3]:  # ìƒìœ„ 3ê°œ í‚¤ì›Œë“œë§Œ
        try:
            import subprocess
            result = subprocess.run(
                ["grep", "-r", "-l", "--include=*.ts", "--include=*.tsx", keyword, PROJECT_PATH],
                capture_output=True, text=True, timeout=10
            )
            for line in result.stdout.strip().split("\n"):
                if line and line not in found_files:
                    found_files.append(line.replace(PROJECT_PATH + "/", ""))
        except Exception:
            pass

    return {"files": found_files[:5]}  # ìƒìœ„ 5ê°œ íŒŒì¼ë§Œ


def calculate_score(issue, code_analysis):
    """í•´ê²° ê°€ëŠ¥ì„± ì ìˆ˜ ê³„ì‚°"""
    score = 0
    reasons = []

    # ì½”ë“œì—ì„œ ê´€ë ¨ íŒŒì¼ ë°œê²¬
    if code_analysis.get("files"):
        score += 3
        reasons.append("ê´€ë ¨ íŒŒì¼ ë°œê²¬ë¨")

    # íŠ¹ì • ì»´í¬ë„ŒíŠ¸/ê¸°ëŠ¥ì— í•œì •
    if issue.get("feature_area"):
        score += 2
        reasons.append(f"ê¸°ëŠ¥ ì˜ì—­: {issue['feature_area']}")

    # ì¬í˜„ ë‹¨ê³„ê°€ ëª…í™•í•¨
    if issue.get("repro_steps"):
        score += 2
        reasons.append("ì¬í˜„ ë‹¨ê³„ ì¡´ì¬")

    # ê´€ë ¨ íŒŒì¼ì´ 3ê°œ ì´í•˜
    if len(code_analysis.get("files", [])) <= 3:
        score += 1
        reasons.append("ë²”ìœ„ê°€ ì¢ìŒ")

    # UI ë²„ê·¸
    ui_keywords = ["ui", "ìŠ¤íƒ€ì¼", "ë ˆì´ì•„ì›ƒ", "í‘œì‹œ", "í™”ë©´", "ë²„íŠ¼", "ì•„ì´ì½˜"]
    if any(kw in issue.get("summary", "").lower() for kw in ui_keywords):
        score += 1
        reasons.append("UI ë²„ê·¸")

    # ë‚œì´ë„ ë¶„ë¥˜
    if score >= 7:
        difficulty = "ğŸŸ¢ ì‰¬ì›€"
    elif score >= 4:
        difficulty = "ğŸŸ¡ ë³´í†µ"
    elif score >= 1:
        difficulty = "ğŸ”´ ì–´ë ¤ì›€"
    else:
        difficulty = "âšª ë¶„ì„ ë¶ˆê°€"

    return {
        "score": score,
        "difficulty": difficulty,
        "reasons": reasons
    }


def generate_report(analyzed_issues, excluded_issues, today):
    """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""
    REPORT_DIR.mkdir(parents=True, exist_ok=True)
    report_path = REPORT_DIR / f"backlog-analysis-{today}.md"

    # ë‚œì´ë„ë³„ ë¶„ë¥˜
    easy = [i for i in analyzed_issues if i["analysis"]["score"] >= 7]
    medium = [i for i in analyzed_issues if 4 <= i["analysis"]["score"] < 7]
    hard = [i for i in analyzed_issues if 1 <= i["analysis"]["score"] < 4]
    unknown = [i for i in analyzed_issues if i["analysis"]["score"] == 0]

    # ì œì™¸ í‹°ì¼“ ë¶„ë¥˜
    excluded_by_freq = {"Random": [], "Once": [], "Sometimes": []}
    for issue in excluded_issues:
        freq = issue.get("frequency", "Unknown")
        if freq in excluded_by_freq:
            excluded_by_freq[freq].append(issue)

    report = f"""# ë°±ë¡œê·¸ ë²„ê·¸ ë¶„ì„ - {today}

## ìš”ì•½
- ë¶„ì„ ëŒ€ìƒ: {len(analyzed_issues) + len(excluded_issues)}ê°œ (ìµœì‹  ìƒì„±ìˆœ)
- í•´ê²° ê°€ëŠ¥ (Always): {len(analyzed_issues)}ê°œ
- ì œì™¸ë¨: {len(excluded_issues)}ê°œ (Random {len(excluded_by_freq['Random'])}, Once {len(excluded_by_freq['Once'])}, Sometimes {len(excluded_by_freq['Sometimes'])})

## í•´ê²° ê°€ëŠ¥í•œ ë²„ê·¸ (Always)

"""

    def format_issue_section(issues, title):
        if not issues:
            return f"### {title}\n\nì—†ìŒ\n\n"

        section = f"### {title}\n\n"
        for issue in issues:
            files = issue.get("code_analysis", {}).get("files", [])
            files_str = "\n".join([f"  - `{f}`" for f in files[:3]]) if files else "  - ì½”ë“œë² ì´ìŠ¤ ì ‘ê·¼ ë¶ˆê°€"
            reasons = ", ".join(issue["analysis"]["reasons"]) if issue["analysis"]["reasons"] else "ë¶„ì„ ì •ë³´ ë¶€ì¡±"

            section += f"""#### [{issue['key']}]({issue['url']}) {issue['summary']}
- **ìƒì„±ì¼**: {issue['created']}
- **Jira ìš°ì„ ìˆœìœ„**: {issue['priority']}
- **ë°œìƒ ë¹ˆë„**: {issue['frequency']}
- **ì˜ˆìƒ ìˆ˜ì • íŒŒì¼**:
{files_str}
- **ë¶„ì„ ê·¼ê±°**: {reasons}

"""
        return section

    report += format_issue_section(easy, "ğŸŸ¢ ì‰¬ì›€ (1-2ì‹œê°„)")
    report += format_issue_section(medium, "ğŸŸ¡ ë³´í†µ (ë°˜ë‚˜ì ˆ)")
    report += format_issue_section(hard, "ğŸ”´ ì–´ë ¤ì›€ (1ì¼+)")
    if unknown:
        report += format_issue_section(unknown, "âšª ë¶„ì„ ë¶ˆê°€")

    # ì œì™¸ëœ í‹°ì¼“
    report += """## ì œì™¸ëœ í‹°ì¼“

"""

    for freq_name, freq_issues in excluded_by_freq.items():
        desc = {"Random": "ê°„í—ì  ë°œìƒ", "Once": "1íšŒì„± - ì¬í˜„ ì–´ë ¤ì›€", "Sometimes": "ê°€ë” ë°œìƒ"}
        report += f"### {freq_name} ({desc.get(freq_name, '')})\n\n"
        if freq_issues:
            report += "| í‹°ì¼“ | ìƒì„±ì¼ | ìš°ì„ ìˆœìœ„ | ì œëª© |\n"
            report += "|------|--------|----------|------|\n"
            for issue in freq_issues:
                report += f"| [{issue['key']}]({issue['url']}) | {issue['created']} | {issue['priority']} | {issue['summary'][:40]}... |\n"
        else:
            report += "ì—†ìŒ\n"
        report += "\n"

    # ê¶Œì¥ ì²˜ë¦¬ ìˆœì„œ
    report += """## ê¶Œì¥ ì²˜ë¦¬ ìˆœì„œ

1. **ì¦‰ì‹œ ì²˜ë¦¬** - ì‰¬ì›€ + P1/P2 ìš°ì„ ìˆœìœ„
2. **ì´ë²ˆ ìŠ¤í”„ë¦°íŠ¸** - ë³´í†µ ë‚œì´ë„
3. **ë‹¤ìŒ ìŠ¤í”„ë¦°íŠ¸** - ì–´ë ¤ì›€ ë‚œì´ë„
4. **ì¶”ê°€ ë¶„ì„ í•„ìš”** - ë¶„ì„ ë¶ˆê°€ í‹°ì¼“
"""

    report_path.write_text(report, encoding="utf-8")
    print(f"ğŸ“„ ë¦¬í¬íŠ¸ ìƒì„±: {report_path}")

    return {
        "path": str(report_path),
        "easy": easy,
        "medium": medium,
        "hard": hard,
        "excluded": excluded_issues
    }


def send_slack_notification(report_data, today, dry_run=False):
    """Slack ì•Œë¦¼ ì „ì†¡"""
    easy = report_data["easy"]
    medium = report_data["medium"]
    hard = report_data["hard"]
    excluded = report_data["excluded"]

    total = len(easy) + len(medium) + len(hard)

    def format_issues(issues, limit=5):
        if not issues:
            return "ì—†ìŒ"
        lines = []
        for issue in issues[:limit]:
            files = issue.get("code_analysis", {}).get("files", [])
            file_hint = f"`{files[0].split('/')[-1]}`" if files else ""
            lines.append(f"â€¢ <{issue['url']}|{issue['key']}> {issue['summary'][:30]}...")
            if file_hint:
                lines.append(f"  â”” {file_hint}")
        return "\n".join(lines)

    blocks = [
        {
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": f"ğŸ” ë°±ë¡œê·¸ ë²„ê·¸ ë¶„ì„ - {today}"
            }
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ë¶„ì„ ê²°ê³¼*: {total + len(excluded)}ê°œ ì¤‘ {total}ê°œ í•´ê²° ê°€ëŠ¥ (Always)\nâ­ï¸ ì œì™¸: {len(excluded)}ê°œ"
            }
        },
        {"type": "divider"}
    ]

    if easy:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ğŸŸ¢ ì‰¬ì›€ ({len(easy)}ê°œ)*\n{format_issues(easy)}"
            }
        })

    if medium:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ğŸŸ¡ ë³´í†µ ({len(medium)}ê°œ)*\n{format_issues(medium)}"
            }
        })

    if hard:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ğŸ”´ ì–´ë ¤ì›€ ({len(hard)}ê°œ)*\n{format_issues(hard)}"
            }
        })

    blocks.append({
        "type": "context",
        "elements": [{
            "type": "mrkdwn",
            "text": f"ğŸ“„ ìƒì„¸ ë¶„ì„: `reports/backlog-analysis-{today}.md`"
        }]
    })

    payload = json.dumps({"blocks": blocks}).encode("utf-8")

    if dry_run:
        print("\nğŸ“¤ Slack ë©”ì‹œì§€ (dry-run, ì‹¤ì œ ì „ì†¡ ì•ˆí•¨):")
        print(json.dumps({"blocks": blocks}, indent=2, ensure_ascii=False))
        return True

    req = urllib.request.Request(SLACK_WEBHOOK, data=payload, headers={
        "Content-Type": "application/json; charset=utf-8"
    })

    try:
        with urllib.request.urlopen(req, timeout=10) as resp:
            print("âœ… Slack ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
            return True
    except Exception as e:
        print(f"âŒ Slack ì „ì†¡ ì‹¤íŒ¨: {e}")
        return False


def main():
    dry_run = "--dry-run" in sys.argv
    today = datetime.now().strftime("%Y-%m-%d")

    print(f"ğŸ” ë°±ë¡œê·¸ ë²„ê·¸ ë¶„ì„ ì‹œì‘ - {today}")
    print(f"   ëª¨ë“œ: {'ë¶„ì„ë§Œ (dry-run)' if dry_run else 'ë¶„ì„ + Slack ì „ì†¡'}")
    print()

    # 1. í™˜ê²½ í™•ì¸
    if not check_env():
        sys.exit(1)

    # 2. ë°±ë¡œê·¸ ì¡°íšŒ
    print("\nğŸ“‹ ë°±ë¡œê·¸ ì¡°íšŒ ì¤‘...")
    backlog = fetch_backlog()
    if not backlog:
        print("âŒ ë°±ë¡œê·¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì¡°íšŒ ì‹¤íŒ¨")
        sys.exit(1)
    print(f"   {len(backlog)}ê°œ í‹°ì¼“ ì¡°íšŒë¨")

    # 3. í‹°ì¼“ ë¶„ì„
    print("\nğŸ” í‹°ì¼“ ë¶„ì„ ì¤‘...")
    analyzed_issues = []
    excluded_issues = []

    for issue in backlog:
        key = issue.get("key", "")
        print(f"   {key} ë¶„ì„ ì¤‘...", end=" ")

        # ìƒì„¸ ì •ë³´ ì¡°íšŒ
        detail = fetch_issue_detail(key)
        if not detail:
            print("âš ï¸ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨")
            continue

        # ë¶„ì„
        analyzed = analyze_issue(detail)

        # ë°œìƒ ë¹ˆë„ë¡œ í•„í„°ë§
        if analyzed["frequency"] in EXCLUDE_FREQUENCIES:
            print(f"â­ï¸ ì œì™¸ ({analyzed['frequency']})")
            excluded_issues.append(analyzed)
            continue

        # ì½”ë“œë² ì´ìŠ¤ ë¶„ì„
        keywords = [analyzed["summary"]]
        if analyzed["feature_area"]:
            keywords.append(analyzed["feature_area"])

        code_analysis = search_codebase(keywords, analyzed["feature_area"])
        analyzed["code_analysis"] = code_analysis

        # ì ìˆ˜ ê³„ì‚°
        analysis = calculate_score(analyzed, code_analysis)
        analyzed["analysis"] = analysis

        print(f"âœ… {analysis['difficulty']}")
        analyzed_issues.append(analyzed)

    # 4. ë¦¬í¬íŠ¸ ìƒì„±
    print("\nğŸ“ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
    report_data = generate_report(analyzed_issues, excluded_issues, today)

    # 5. Slack ì•Œë¦¼
    print("\nğŸ“¤ Slack ì•Œë¦¼ ì „ì†¡ ì¤‘...")
    send_slack_notification(report_data, today, dry_run=dry_run)

    print("\nâœ… ë¶„ì„ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
